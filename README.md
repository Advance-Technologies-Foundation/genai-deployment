
# GenAI Setup Guide

# Docker compose

This document provides a step-by-step procedure to deploy and configure the GenAI service using Docker Compose on a Linux machine, and integrate it with Creatio.

---

## Table of Contents

1. [Services Overview](#services-overview)  
2. [Install Docker](#install-docker)  
3. [Install Docker-Compose](#install-docker-compose)  
4. [Download docker compose files](#download-docker-compose-files)  
5. [Set Up Container Variables](#set-up-container-variables)  
6. [Run GenAI Service Containers](#run-genai-service-containers)  
7. [Configure GenAI Functionality in Creatio](#configure-genai-functionality-in-creatio)  
8. [Notes](#notes)

---

## Services Overview

This deployment consists of several core services managed via Docker Compose. Each service plays a key role in the functioning of the GenAI system.

### `enrichment-service`
A web service responsible for handling GenAI requests such as **chat completions**.  
It acts as the main REST API endpoint, processing input text from clients (e.g., Creatio) and returning responses generated by an underlying language model.

### `litellm`
A service that provides an abstraction layer for **Large Language Model (LLM)** APIs.

**Purpose:**
- Enables easy integration with multiple LLM providers such as **OpenAI** and **Azure OpenAI**.
- Offers a **unified API interface** for making chat, completion, and embedding requests.
- Simplifies model management, routing, and provider switching with minimal configuration changes.

### `postgres`
A PostgreSQL database used for storing:
- GenAI configuration data (e.g., promts)
- Operational statistics (e.g., request logs)

---

## Install Docker

Install Docker on a physical or virtual machine running Linux OS to deploy the GenAI components.

Refer to the official Docker installation documentation for Linux (Debian-based distributions):  
https://docs.docker.com/install/linux/docker-ce/debian/

Verify Docker installation by running the following command:

```bash
docker --version
```

---

## Install Docker-Compose

1. Install Docker-Compose on your Linux machine.

Refer to the official Docker-Compose installation guide:  
https://docs.docker.com/compose/install/

Verify Docker-Compose installation by running:

```bash
docker-compose --version
```

---

## Download docker compose files

1. Download and unpack the archive with the setup files from the repository:  
   [GenAI Docker-Compose Setup](https://github.com/Advance-Technologies-Foundation/genai-deployment/archive/refs/heads/main.zip)

2. Go to the docker-compose folder

---

## Set Up Container Variables

Configure the GenAI service containers by setting environment variables in the `.env` file located in the deployment folder. Edit this file to provide the required parameters.

### API Authentication Parameters

Provide parameters depending on the Large Language Model (LLM) service you are using:

#### For OpenAI LLM

| Variable                     | Description                                               |
|------------------------------|-----------------------------------------------------------|
| `OPENAI_MODEL`              | OpenAI provider and model ID (e.g. openai/gpt-4o)         |
| `OPENAI_EMBEDDING_MODEL`    | OpenAI provider and embedding model ID (e.g. openai/gpt-4o)         |
| `OPENAI_API_KEY`              | Your OpenAI API key to authenticate API requests.         |
| `OPENAI_API_KEY_TEXT_EMBEDDING` | *(Optional)* Separate key for OpenAI text embedding service if different from main key. |

#### For Azure OpenAI LLM

| Variable                     | Description                                               |
|------------------------------|-----------------------------------------------------------|
| `AZURE_MODEL`               | Azure provider and model ID (e.g. azure/gpt-4o-2024-11-20)     |
| `AZURE_EMBEDDING_MODEL`     | Azure provider and embedding model ID (e.g. azure/gpt-4o-2024-11-20)      |
| `AZURE_API_KEY`               | Azure API key (subscription key) for authentication.      |
| `AZURE_API_TEXT_EMBEDDING`   | *(Optional)* Separate API key or token for Azure text embedding service. |
| `AZURE_DEPLOYMENTID`          | Deployment ID or name of the Azure OpenAI model to use.   |
| `AZURE_RESOURCENAME`          | Name of your Azure OpenAI resource instance for endpoint construction. |
| `AZURE_API_BASE`          | The base URL of your Azure OpenAI endpoint. This is typically in the format https://<your-resource-name>.openai.azure.com. It's used to construct full API request URLs. |
| `AZURE_EMBEDDING_API_BASE`          | The base URL of your Azure OpenAI endpoint (text embeddings model). This is typically in the format https://<your-resource-name>.openai.azure.com. It's used to construct full API request URLs. |
| `AZURE_API_VERSION`          | The version of the Azure OpenAI API to use. For example: 2023-07-01-preview. This must match a supported version by Azure and may change over time as the API evolves. |

### Default Models

Set the default models used by GenAI:

| Variable                     | Description                                               |
|------------------------------|-----------------------------------------------------------|
| `GenAI__DefaultModel`         | Identifier or name of the default language generation model (for text completion or chat). Take it from \etc\litellm-config.yaml (model_name parameter of the corresponding model) |
| `GenAI__EmbeddingsModel`      | Identifier or name of the default text embeddings model. Take it from \etc\litellm-config.yaml (model_name parameter of the corresponding model) |

---

## Run GenAI Service Containers

1. Open a terminal and navigate to the docker-compose folder.

2. Run the following command to start the GenAI service containers in detached mode:

```bash
docker-compose up -d
```

---

## Configure GenAI Functionality in Creatio

1. Open Creatio and go to **System Settings**.

2. Locate the setting named **Account enrichment service url**.

3. Set its value to:

```
http://[your_server_ip_address]:5006
```

Replace `[your_server_ip_address]` with the actual IP address or hostname of the server where the GenAI Docker containers are running.

## Notes

- This deployment uses **Docker Compose** for orchestration.  
- Ensure that the firewall allows inbound traffic on port **5006** for Creatio to communicate with the GenAI service.  
- Keep the `.env` file secure, as it contains sensitive API keys.  

---

# GenAI Deployment on Kubernetes using Helm

This guide outlines the steps to deploy the GenAI enrichment service on a Kubernetes cluster using Helm. It includes instructions for environment setup, configuration, deployment, and integration with Creatio.

---

## Table of Contents

1. [Prerequisites](#prerequisites)
2. [Download Helm Files](#download-helm-files)
3. [Configuration: `values.onsite.yaml`](#configuration-valuesonsiteyaml)
   - [OpenAI Model Configuration](#openai-model-configuration)
   - [Azure Model Configuration](#azure-model-configuration)
   - [Default Model Configuration](#default-model-configuration)
4. [Create Docker Registry Secret](#create-docker-registry-secret)
5. [Deploy with Helm](#deploy-with-helm)
6. [Obtain Ingress Host and NodePort](#obtain-ingress-host-and-nodeport)
7. [Configure GenAI in Creatio](#configure-genai-in-creatio)

---

## Prerequisites

Ensure the following components are set up:

- A **Kubernetes** cluster.  
  See: [Kubernetes Setup Guide](https://kubernetes.io/docs/home/)
- The **Helm** package manager installed.  
  See: [Helm Installation Guide](https://helm.sh/docs/intro/install/)
- Valid **credentials** for accessing `registry.creatio.com`

---

## Download Helm Files

1. Download and extract the setup files from the repository:

   [GenAI Kubernetes Setup - GitHub](https://github.com/Advance-Technologies-Foundation/genai-deployment/archive/refs/heads/main.zip)

2. Navigate to the `helm` directory within the extracted archive.

---

## Configuration: `values.onsite.yaml`

Customize the deployment configuration in the `values.onsite.yaml` file depending on the LLM provider you're using (You can configure parameters for either OpenAI, Azure, or both. Please note that if you are not using one of these providers, the corresponding section should be either commented out or removed entirely.).

### OpenAI Model Configuration

```yaml
appConfig:
  genAI:
    llmProviders:
      models:
        openai:
          - name: <your-model-name>
            model: <your-model-type>
            api_key: <your-openai-api-key>
```

**Parameters:**

- `name`: A reference name for the model
- `model`: The OpenAI model name (e.g., `gpt-4`)
- `api_key`: Your OpenAI API key

### Azure Model Configuration

```yaml
appConfig:
  genAI:
    llmProviders:
      models:
        azure:
          - name: <your-model-name>
            model: <your-model-type>
            resource_name: <your-azure-resource-name>
            api_key: <your-azure-api-key>
```

**Parameters:**

- `name`: A reference name for the model
- `model`: The deployed Azure OpenAI model
- `resource_name`: Azure resource name
- `api_key`: Azure API key

### Default Model Configuration

Define the default models to be used by the enrichment service (take the name from appConfig:genAI:llmProviders:models:<provider(openai or azure)>:- name):

```yaml
appConfig:
  genAI:
    llmProviders:
      defaultModel: <your-default-model-name>
      embeddingsModel: <your-default-embedding-model-name> # Optional
```

Specify the ingress host by setting the DNS name that points to your Linux serverâ€™s public IP in the configuration as follows:

```yaml
ingress:
  enabled: true
  hosts:
    - <your-ingress-hostname>

---

## Create Docker Registry Secret

Create a secret to access the Creatio Docker registry:

```bash
kubectl create secret docker-registry regcred   --docker-server=registry.creatio.com   --docker-username=<your-username>   --docker-password=<your-password>   --kubeconfig=<path-to-your-kubeconfig>
```

---

## Deploy with Helm

From the directory containing the `values.onsite.yaml` file, run:

```bash
helm upgrade --install genai ./enrichment   -f values.onsite.yaml   --kubeconfig <path-to-your-kubeconfig>
```

---

## Obtain Ingress Host and NodePort

1. Get the ingress host:

   ```bash
   kubectl get ingress genai-enrichment
   ```

   Retrieve the value under the `HOSTS` column.

2. Get the service NodePort:

   ```bash
   kubectl get svc genai-enrichment
   ```

   Retrieve the NodePort value under the `PORTS` column.

---

## Configure GenAI in Creatio

1. Log into Creatio and go to **System Settings**.
2. Locate the setting: `Account enrichment service url`.
3. Set its value using the following format:

   ```
   http://<ingress-host>:<node-port>
   ```

   Replace `<ingress-host>` and `<node-port>` with the actual values obtained in the previous step.

---

If you have any questions or require assistance, please refer to the project repository or contact support.

